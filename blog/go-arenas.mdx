---
title: Experimenting With Memory Areans in Go 1.20
sidebar_label: Experimenting With Memory Areans in Go 1.20
slug: /using-memory-arenas-in-go-1-20
date: "2023-01-24"
authors:
  - name: Dmitry Filimonov
    title: Pyroscope CTO
    url: https://github.com/petethepig
    image_url: https://avatars.githubusercontent.com/u/662636?v=4
  - name: ChatGPT
    title: Editor
    url: https://chat.openai.com/
    image_url: https://chat.openai.com/favicon-32x32.png
image: https://user-images.githubusercontent.com/662636/214387129-89b621db-fc0f-4cb7-9e66-877a96affc90.png
---

import {Flamegraph} from '../src/components/Blog/Flamegraph';
import {HighAlloc, HighAllocCPU, AfterChange} from '../src/components/Blog/HighAlloc';

![arenas-blur](https://user-images.githubusercontent.com/662636/215354950-8fcc97e2-4a2b-4afb-804e-78ce18a2212f.jpg)

:::warning

Go arenas are an experimental feature. The API and implementation is completely unsupported and go team makes no guarantees about compatibility or whether it will even continue to exist in any future release.

See [this Github discussion](https://github.com/golang/go/issues/51317#issuecomment-1385623024) for more details.

:::


## Introduction

Go 1.20 introduces the concept of "arenas" for memory management, which can be used to improve the performance of your Go programs. In this blog post, we'll take a look at what arenas are, how they work, how to determine if your programs could benefit from using them, and show you an example of how we used them to optimize one of our services. We also included some reference materials on how to use arenas in your own code.

## What are memory arenas?

Go is a programming language that utilizes garbage collection, meaning that the runtime automatically manages memory allocation and deallocation for the programmer. This eliminates the need for manual memory management, but it comes with a cost. The Go runtime must keep track of every object that is allocated, leading to a performance overhead.

In certain scenarios, such as when an HTTP server processes requests with large protobuf blobs, this can result in the Go runtime spending a lot of time on single allocations, tracking them, and then deallocating them. This can cause a significant performance overhead.

Arenas offer a solution to this problem. To reduce overhead in the example of protobuf blobs, a large chunk of memory (an arena) can be allocated before parsing. This reduces the overhead of many small allocations. All parsed objects can then be placed on the arena, and since these objects belong to the arena, they are no longer tracked by the Go runtime, eliminating garbage collection overhead. Once parsing is completed, the entire arena can be freed at once, further reducing the overhead of freeing many small objects.

## How to identify code that could benefit from arenas

Any code that allocates a lot of small objects could potentially benefit from arenas. But how do you know if your code allocates too many? In our experience, the best way to do that is to profile your program.

Using Pyroscope we were able to get an allocations profile (`alloc_objects`) of one of our [cloud services](https://pyroscope.io/pricing/):

<Flamegraph profileData={HighAlloc}></Flamegraph>
<br/>

You can see that the majority of allocations (`794.87 M`) come from one area of code â€” parsing protobuf encoded pprof files. This is a good candidate for using arenas. But is it still worthwhile to cut down these allocations? Let's take a look at the CPU profile (`cpu`) of the same service:

<Flamegraph profileData={HighAllocCPU}></Flamegraph>
<br/>


Few things stand out:
* most of the work this service performs is indeed related to parsing pprof files, so that means we're on the right track.
* if you search for `runtime.mallocgc` (multiple pink nodes at the bottom) you will see that that function is called a lot in various places and it takes about 16% our total execution time. We can use [use sandwich view](https://user-images.githubusercontent.com/662636/215287900-5ba84463-fd22-4e29-a56e-9e67492d5f88.png) to see exactly which functions call it.
* we can also see that about 6% of the time is spent in `runtime.gcBgMarkWorker` (pink nodes located in the right section of the flamegraph).

So in theory, if we optimized all allocations in this program, we could cut about 16% + 6% = 22% of CPU time. This would translate in 22% cost savings and latency improvements for all of our customers. In practice, it's unlikely that we could truly get these numbers down to zero, but this is still a significant chunk of work that the application performs and it might be worth it to optimize it.

## Optimizations We've Made

If you're interested in following along, there's a [public pull request in the Pyroscope repository](https://github.com/pyroscope-io/pyroscope/pull/1804) that you can use as a reference.

* To begin, we created [a wrapper component](https://github.com/pyroscope-io/pyroscope/pull/1804/files#diff-70ab4bbe796a97ad1a47d7970504296eff36b5307527ae2806d2b50f94f83a45) that is responsible for dealing with slices or structs. If arenas are enabled, this component allocates the slices using an arena, otherwise it uses the standard `make` function. We do this by using build tags (`//go:build goexperiment.arenas`). This allows for easy switching between arena allocation and standard allocation at build time.

* We then added [initialization](https://github.com/pyroscope-io/pyroscope/pull/1804/files#diff-32bf8c53a15c8a5f7eb424b21c8502dc4905ec3caa28fac50f64277361ae746fR417) and [cleanup](https://github.com/pyroscope-io/pyroscope/pull/1804/files#diff-34edf37e55842273380ee6cb31c9245f31ed25aa6d7898b0f2c25145f17d8ea0R170) calls for arenas around the parser code.

* After that we [replaced regular `make` calls with make calls from our wrapper component](https://github.com/pyroscope-io/pyroscope/pull/1804/files#diff-abe15b6d3634170650f86bb7283aa15265de2197cffa969deda2dd5b26fcecd9R89-R92).

* Finally, we built pyroscope with arenas enabled and gradually deployed it to our production environment of [Pyroscope Cloud](https://pyroscope.io/pricing).

<Flamegraph profileData={AfterChange}></Flamegraph>
<br/>

In our case, we were able to reduce the overhead of `runtime.mallocgc` calls from 16% to 4% and the garbage collection overhead from 6% to 2.5%. Some of `runtime.mallocgc` calls were replaced with arena-specific equivalent (`runtime.(*userArena).alloc`), adding 4.5% back. This equates to about (16% + 6%) - (4% + 2.5% + 4.5%) = **11% of CPU time saved**. We cross-referenced this against CPU utilization charts that we get from the OS level and saw the same reduction of CPU utilization. This translates directly into 11% cost savings on cloud bills for that particular service, making it a worthwhile improvement.


## Tradeoffs and Drawbacks

While arenas can provide performance benefits, it's important to consider the trade-offs before using them. The main drawback of using arenas is that when you use arenas you now have to manage memory manually and if you're not careful that may lead to serious problems:

* Failing to properly free memory can lead to **memory leaks**.
* Attempting to access objects from a previously freed arena may cause **program crashes**.

Here's our recommendations:
* Only use arenas in critical code paths. Do not use them everywhere.
* Pay close attention to the lifecycle of the objects created on the arena. make sure you don't leak them to other components of your program where objects may outlive the arena.
* Use `defer a.Free()` to make sure that you don't forget to free memory.
* Use `arena.Clone()` to clone objects back to the heap if you want to use them after an arena was freed.

The other major drawback at the moment is that Go arenas are an experimental feature. The API and implementation is completely unsupported and go team makes no guarantees about compatibility or whether it will even continue to exist in any future release.

We recommend that you extract all arena-related code into a separate package and use build tags to make sure that it's easy to remove it from your codebase if you decide to stop using arenas. [Our code](https://github.com/pyroscope-io/pyroscope/pull/1804/files#diff-70ab4bbe796a97ad1a47d7970504296eff36b5307527ae2806d2b50f94f83a45) can serve as a demonstration of this approach.


## How do I use memory arenas?

:::warning
Go arenas are an experimental feature. The API and implementation is completely unsupported and go team makes no guarantees about compatibility or whether it will even continue to exist in any future release.
:::

To use arenas in your own programs, you will need to make sure that your program is compiled with the Go 1.20 runtime. You can check the version of the Go runtime by running the following command:

```shell
$ go version
> go version go1.20rc3 linux/amd64
```

You can download the pre-release version of go 1.20 from [official go website](https://go.dev/dl/#go1.20rc3).

Once you have confirmed that you are running Go 1.20 or later, you can start using arenas in your program. Memory arenas are experimental so you will need to enable them by setting the `GOEXPERIMENT` environment variable to `arenas`:

```shell
GOEXPERIMENT=arenas go build main.go
```

### Working with single structs

Here's a example where we create an arena, allocate one object on it, then free it:

```go
package main

import (
	"arena"
	"fmt"
)

type User struct {
	loginAttempts int
}

func main() {
	a := arena.NewArena()      // create an arena
	user := arena.New[User](a) // allocate one struct on the arena
	user.loginAttempts++       // work with a struct as you normally would

	// After you're done working with structs
	//   on an arena, you can free it
	a.Free()

	// CAUTION: you should never access structs allocated
	//   on an arena after it was freed
	fmt.Printf("this may panic: %d\n", user.loginAttempts)
}
```

### Slices

Allocating single objects is great, but in practice you will most likely be using arenas to allocate slices. Here's an example of how you can use arenas to do that:

```go
a := arena.NewArena()
defer a.Free()

user := arena.New[User](a)                  // allocate one struct
users := arena.MakeSlice[User](a, 100, 100) // allocate a slice
```

### Cloning objects back to heap

Sometimes you may want to clone an object back to the heap. This is useful if you want for some objects to outlive a specific arena. Here's a practical example where you have a function that takes a huge blob of data, parses it into a slice of structs, and then returns a single struct from that slice:

```go
func findUserByID(blob []byte, len int, id string) *User {
	// set up an arena
	a := arena.NewArena()
	defer a.Free()

	users := arena.MakeSlice[User](a, len, len) // allocate a slice
	json.Unmarshal(blob, users)                 // parse JSON blob

	for _, user := range users {
		if user.ID == id {
			// arena.Clone allows you to clone
			//   an object back to the heap
			// This way you can reuse it later,
			//   even after an arena was freed
			return arena.Clone[*User](&user)
		}
	}
}
```

## Conclusion

Arenas are a powerful tool for optimizing Go programs, particularly in scenarios where your programs spend significant amount of time parsing large protobuf or JSON blobs. They have the potential to provide significant performance improvements, but it is important to note that they are an experimental feature and there are no guarantees of compatibility or continued existence in future releases.

We recommend that you profile your applications and try using arenas  on a limited portion of your codebase and [report your findings to the go team](https://github.com/golang/go/issues/51317).
